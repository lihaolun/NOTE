# 离线数仓：环境搭建

- [离线数仓：环境搭建](#离线数仓环境搭建)
  - [一、总体结构](#一总体结构)
  - [二、准备工作](#二准备工作)
    - [2.1、准备三台虚拟机](#21准备三台虚拟机)
    - [2.2、SSH无密登录配置](#22ssh无密登录配置)
    - [2.3、公用脚本](#23公用脚本)
  - [三、安装JDK](#三安装jdk)
  - [四、安装Hadoop](#四安装hadoop)
  - [五、安装Zookeeper](#五安装zookeeper)
  - [六、安装kafka](#六安装kafka)
  - [七、安装Flume](#七安装flume)
  - [八、模拟日志的生成](#八模拟日志的生成)
    - [8.1、模拟生成log日志](#81模拟生成log日志)
    - [8.2、集群日志生成脚本](#82集群日志生成脚本)
    - [8.3、日志采集Flume配置](#83日志采集flume配置)
    - [8.4、Flume拦截器](#84flume拦截器)
    - [8.5、日志采集Flume启动停止脚本](#85日志采集flume启动停止脚本)
    - [8.6、日志消费Flume配置](#86日志消费flume配置)
    - [8.7、日志消费Flume启动停止脚本](#87日志消费flume启动停止脚本)
    - [8.8、采集通道启动/停止脚本](#88采集通道启动停止脚本)
    - [8.9、数据通道测试](#89数据通道测试)

## 一、总体结构

![1593743034188](https://gitee.com/wangzj6666666/bigdata-img/raw/master/data_warehouse_offline/总体架构.png)

## 二、准备工作

### 2.1、准备三台虚拟机
 
- 更改主机名hadoop102、hadoop103、hadoop104
- 配置好IP
- 创建好用户atguigu
- 创建插件安装路 /opt/mudule
- 创建安装包存放路径 /opt/software
- 提前安装插件

```shell
sudo yum install -y epel-release
sudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop
```

- hadoop102、hadoop103、hadoop104关闭防火墙

```shell
# 关闭防火墙服务
sudo systemctl stop firewalld.service
# 禁止自启动
sudo systemctl disable firewalld.service 
```



### 2.2、SSH无密登录配置

1）配置ssh

- 基本语法

ssh另一台电脑的ip地址

```shell
ssh hadoop103
```

- ssh连接时出现Host key verification failed的解决方法

```shell
The authenticity of host '192.168.1.103 (192.168.1.103)' can't be established.
RSA key fingerprint is cf:1e:de:d7:d0:4c:2d:98:60:b4:fd:ae:b1:2d:ad:07.
Are you sure you want to continue connecting (yes/no)? 
```

解决方案如下：直接输入yes



2）无密钥配置

三台服务器都需要配置

- 生成公钥和私钥

```shell
ssh-keygen -t rsa
```

- 将公钥拷贝到要免密登录的目标机器上

```shell
ssh-copy-id hadoop102
ssh-copy-id hadoop103
ssh-copy-id hadoop104
```

注意：

还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；

还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。



### 2.3、公用脚本

1）集群分发脚本（集群分发文件）

创建分发脚本

```shell
vim /home/atguigu/bin/xsync
```

```shell
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi
#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
  echo ====================  $host  ====================
  #3. 遍历所有目录，挨个发送
  for file in $@
  do
    #4 判断文件是否存在
    if [ -e $file ]
    then
      #5. 获取父目录
      pdir=$(cd -P $(dirname $file); pwd)
      #7. 获取当前文件的名称
      fname=$(basename $file)
      ssh $host "mkdir -p $pdir"
      rsync -av $pdir/$fname $host:$pdir
    else
      echo $file does not exists!
    fi
  done
done
```

设置权限

```shell
chmod 777 xsync
```



2）集群指令脚本

创建xcall.sh脚本

```shell
vim /home/atguigu/bin/xcall.sh
```

```shell
#! /bin/bash

for i in hadoop102 hadoop103 hadoop104
do
    echo --------- $i ----------
    ssh $i "$*"
done
```

设置权限

```shell
chmod 777 xcall.sh
```

这样xcall.sh 指令就可以在集群中同时执行，比如查看集群中的java进程

```shell
xcall.sh jps
```





## 三、安装JDK

1）上传JDK安装包/opt/software/

```shel
cd /opt/software/
```

2）解压JDK到/opt/module目录下

```shell
[atguigu@hadoop102 software]# tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/
```

3）配置JDK环境变量

- 新建/etc/profile.d/my_env.sh文件

```shell
[atguigu@hadoop102 module]# sudo vim /etc/profile.d/my_env.sh
```

添加如下内容

```shell
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
```

- 保存后退出   :wq
- 重启xshell窗口，让环境变量生效

```
source /etc/profile.d/my_env.sh
```

4）测试JDK是否安装成功

```shell
[atguigu@hadoop102 module]# java -version
```

如果能看到以下结果、则Java正常安装

```shell
java version "1.8.0_212"
```

5）分发JDK 

```shell
[atguigu@hadoop102 module]$ xsync /opt/module/jdk1.8.0_212/
```

6）分发环境变量配置文件

```shell
[atguigu@hadoop102 module]$ sudo /home/atguigu/bin/xsync /etc/profile.d/my_env.sh
```

7）分别在hadoop103、hadoop104上执行source

```shell
[atguigu@hadoop103 module]$ source /etc/profile.d/my_env.s
[atguigu@hadoop104 module]$ source /etc/profile.d/my_env.sh
```



## 四、安装Hadoop

1）进入到Hadoop安装包路径下

```shell
[atguigu@hadoop102 ~]$ cd /opt/software/
```

2）解压安装文件到/opt/module下面

```shell
[atguigu@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/
```

3）查看是否解压成功

```shell
[atguigu@hadoop102 software]$ ls /opt/module/
hadoop-3.1.3
```

6）将Hadoop添加到环境变量，打开/etc/profile.d/my_env.sh文件

```shell
[atguigu@hadoop102 hadoop-3.1.3]$ sudo vim /etc/profile.d/my_env.sh
```

在profile文件末尾添加JDK路径：（shitf+g）

```shell
##HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

分发环境变量文件

```shell
[atguigu@hadoop102 hadoop-3.1.3]$ sudo /home/atguigu/bin/xsync /etc/profile.d/my_env.sh
```

source 使之生效（3台节点）

```shell
source /etc/profile.d/my_env.sh
```

7）核心配置文件，配置core-site.xml

```shell
[atguigu@hadoop102 .ssh]$ cd /opt/module/hadoop-3.1.3/etc/hadoop/
[atguigu@hadoop102 hadoop]$ vim core-site.xml
```

文件内容如下：

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop102:8020</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>
    <property>
        <name>hadoop.proxyuser.atguigu.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.atguigu.groups</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>atguigu</value>
    </property>
</configuration>

```

8）HDFS配置文件，配置hdfs-site.xml

```shell
[atguigu@hadoop102 hadoop]$ vim hdfs-site.xml
```

文件内容如下：

```xml
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
</configuration>
```

9）YARN配置文件，配置yarn-site.xml

```shell
[atguigu@hadoop102 hadoop]$ vim yarn-site.xml
```

文件内容如下：

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
</property>
<property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>4096</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>4096</value>
    </property>
</configuration>
```

10）MapReduce配置文件，配置mapred-site.xml

```shell
[atguigu@hadoop102 hadoop]$ vim mapred-site.xml
```

文件内容如下：

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

11）配置workers

```shell
[atguigu@hadoop102 hadoop]$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
```

在该文件中增加如下内容：

```txt
hadoop102
hadoop103
hadoop104
```

注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。

12）配置历史服务器，为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：

- 配置mapred-site.xml

```shell
[atguigu@hadoop102 hadoop]$vi mapred-site.xml
```

在该文件里面增加如下配置。

```xml
<!-- 历史服务器端地址 -->
<property>
    <name>mapreduce.jobhistory.address</name>
    <value>hadoop102:10020</value>
</property>

<!-- 历史服务器web端地址 -->
<property>
    <name>mapreduce.jobhistory.webapp.address</name>
    <value>hadoop102:19888</value>
</property>
```

13）配置日志的聚集

日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。

日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。

注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryManager。

开启日志聚集功能具体步骤如下：

- 配置yarn-site.xml

```shell
[atguigu@hadoop102 hadoop]$ vim yarn-site.xml
```

在该文件里面增加如下配置。

```xml
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<property>  
    <name>yarn.log.server.url</name>  
    <value>http://hadoop102:19888/jobhistory/logs</value>  
</property> 
<property>
    <name>yarn.log-aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```

  14）分发Hadoop

```shell
[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/
```

15）如果集群是第一次启动，需要在hadoop102节点格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）

```shell
[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode -format
```

16）群起脚本

```shell
#!/bin/bash
if [ $# -lt 1 ]
then
        echo "No Args Input Error!!!!!"
        exit
fi

case $1 in
"start")
        echo "====================== start hdfs ============================"  
        ssh hadoop102 /opt/module/hadoop-3.1.3/sbin/start-dfs.sh
        echo "====================== start yarn ============================"
        ssh hadoop103 /opt/module/hadoop-3.1.3/sbin/start-yarn.sh
;;
"stop")
        echo "====================== stop yarn ============================" 
        ssh hadoop103 /opt/module/hadoop-3.1.3/sbin/stop-yarn.sh
        echo "====================== stop hdfs ============================" 
        ssh hadoop102 /opt/module/hadoop-3.1.3/sbin/stop-dfs.sh
;;
*)
        echo "Input Args Error !!!"
;;
esac

```

17）Web端查看HDFS的Web页面：http://hadoop102:9870/



18）将编译好后的hadoop-lzo-0.4.20.jar 放入hadoop-3.1.3/share/hadoop/common/

```shell
[atguigu@hadoop102 common]$ pwd
/opt/module/hadoop-3.1.3/share/hadoop/common

[atguigu@hadoop102 common]$ ls
hadoop-lzo-0.4.20.jar
```

3）同步hadoop-lzo-0.4.20.jar到hadoop103、hadoop104

```shell
[atguigu@hadoop102 common]$ xsync hadoop-lzo-0.4.20.jar
```

4）core-site.xml增加配置支持LZO压缩，分发到三台服务器

```xml
<property>
        <name>io.compression.codecs</name>
        <value>
            org.apache.hadoop.io.compress.GzipCodec,
            org.apache.hadoop.io.compress.DefaultCodec,
            org.apache.hadoop.io.compress.BZip2Codec,
            org.apache.hadoop.io.compress.SnappyCodec,
            com.hadoop.compression.lzo.LzoCodec,
            com.hadoop.compression.lzo.LzopCodec
        </value>
    </property>

    <property>
        <name>io.compression.codec.lzo.class</name>
        <value>com.hadoop.compression.lzo.LzoCodec</value>
    </property>

```



## 五、安装Zookeeper

1）集群规划，在hadoop102、hadoop103和hadoop104三个节点上部署Zookeeper。

2）解压安装

- 解压Zookeeper安装包到/opt/module/目录下

```shell
[atguigu@hadoop102 software]$ tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /opt/module/
```

- 修改/opt/module/apache-zookeeper-3.5.7-bin名称为zookeeper-3.5.7

```shell
[atguigu@hadoop102 module]$ mv apache-zookeeper-3.5.7-bin/ zookeeper-3.5.7
```

- 同步/opt/module/zookeeper-3.5.7目录内容到hadoop103、hadoop104

```shell
[atguigu@hadoop102 module]$ xsync zookeeper-3.5.7/
```

3）配置服务器编号

- 在/opt/module/zookeeper-3.5.7/这个目录下创建zkData

```shell
[atguigu@hadoop102 zookeeper-3.5.7]$ mkdir zkData
```

- 在/opt/module/zookeeper-3.5.7/zkData目录下创建一个myid的文件

```shell
[atguigu@hadoop102 zookeeper-3.5.7]$cd /opt/module/zookeeper-3.5.7/zkData
[atguigu@hadoop102 zkData]$ vi myid
```

添加myid文件，注意一定要在linux里面创建，在notepad++里面很可能乱码

在文件中添加与server对应的编号：

```txt
2
```

- 拷贝配置好的zookeeper到其他机器上

```shell
[atguigu@hadoop102 zkData]$ xsync myid
```

并分别在hadoop103、hadoop104上修改myid文件中内容为3、4

4）配置zoo.cfg文件

- 重命名/opt/module/zookeeper-3.5.7/conf这个目录下的zoo_sample.cfg为zoo.cfg

```shell
[atguigu@hadoop102 zookeeper-3.5.7]$ cd /opt/module/zookeeper-3.5.7/conf
[atguigu@hadoop102 conf]$ mv zoo_sample.cfg zoo.cfg
```

- 打开zoo.cfg文件

```shell
[atguigu@hadoop102 conf]$ vim zoo.cfg
```

- 修改数据存储路径配置

```shell
dataDir=/opt/module/zookeeper-3.5.7/zkData
```

- 增加如下配置

```txt
#######################cluster##########################

server.2=hadoop102:2888:3888
server.3=hadoop103:2888:3888
server.4=hadoop104:2888:3888
```

配置参数解读

server.A=B:C:D。

A是一个数字，表示这个是第几号服务器；

集群模式下配置一个文件myid，这个文件在dataDir目录下，这个文件里面有一个数据就是A的值，Zookeeper启动时读取此文件，拿到里面的数据与zoo.cfg里面的配置信息比较从而判断到底是哪个server。

B是这个服务器的地址；

C是这个服务器Follower与集群中的Leader服务器交换信息的端口；

D是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。



5）同步zoo.cfg配置文件

```shell
[atguigu@hadoop102 conf]$ xsync zoo.cfg
```

6）集群脚本

```shell
#! /bin/bash

case $1 in
"start"){
        for i in hadoop102 hadoop103 hadoop104
        do
        echo ---------- zookeeper $i 启动 ------------
                ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh start"
        done
};;
"stop"){
        for i in hadoop102 hadoop103 hadoop104
        do
        echo ---------- zookeeper $i 停止 ------------    
                ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop"
        done
};;
"status"){
        for i in hadoop102 hadoop103 hadoop104
        do
        echo ---------- zookeeper $i 状态 ------------    
                ssh $i "/opt/module/zookeeper-3.5.7/bin/zkServer.sh status"
        done
};;
esac
```



## 六、安装kafka

1）解压安装包

```shell
[atguigu@hadoop102 software]$ tar -zxvf kafka_2.11-2.4.1.tgz -C /opt/module/
```

2）修改解压后的文件名称

```shell
[atguigu@hadoop102 software]$ cd /opt/module/kafka_2.11-2.4.1/
[atguigu@hadoop102 module]$ mv kafka_2.11-2.4.1/ kafka
```

3）在/opt/module/kafka目录下创建logs文件夹

```shell
[atguigu@hadoop102 kafka]$ mkdir logs
```

4）修改配置文件

```shell
[atguigu@hadoop102 kafka]$ cd config/
[atguigu@hadoop102 config]$ vi server.properties
```

修改或者增加以下内容：

```properties
#broker的全局唯一编号，不能重复
broker.id=0
#删除topic功能使能
delete.topic.enable=true
#kafka运行日志存放的路径
log.dirs=/opt/module/kafka/logs
#配置连接Zookeeper集群地址
zookeeper.connect=hadoop102:2181,hadoop103:2181,hadoop104:2181/kafka
```

5）配置环境变量

```shell
[atguigu@hadoop102 module]$ sudo vi /etc/profile.d/my_env.sh
```

 添加如下内容

```shell
#KAFKA_HOME
export KAFKA_HOME=/opt/module/kafka
export PATH=$PATH:$KAFKA_HOME/bin
```

 source使之生效

```shell
[atguigu@hadoop102 module]$ source /etc/profile.d/my_env.sh
```

6）分发安装包

```shell
[atguigu@hadoop102 module]$ xsync kafka/
```

注意：分发之后记得配置其他机器的环境变量

7）分别在hadoop103和hadoop104上修改配置文件/opt/module/kafka/config/server.properties中的broker.id=1、broker.id=2 (注：broker.id不得重复)

8）kafka群起脚本

- 在/home/atguigu/bin目录下创建脚本kf.sh

```
[atguigu@hadoop102 bin]$ vim kf.sh
```

在脚本中填写如下内容

```shell
#! /bin/bash

case $1 in
"start"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo " --------启动 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-start.sh -daemon /opt/module/kafka/config/server.properties "
    done
};;
"stop"){
    for i in hadoop102 hadoop103 hadoop104
    do
        echo " --------停止 $i Kafka-------"
        ssh $i "/opt/module/kafka/bin/kafka-server-stop.sh stop"
    done
};;
esac
```

9）增加脚本执行权限

```shell
[atguigu@hadoop102 bin]$ chmod 777 kf.sh
```

10）kf集群启动脚本

```shell
[atguigu@hadoop102 module]$ kf.sh start
```

11）kf集群停止脚本

```shell
[atguigu@hadoop102 module]$ kf.sh start
```



## 七、安装Flume

1）将 apache-flume-1.9.0-bin.tar.gz 上传到 linux 的 /opt/software 目录下

2）解压 apache-flume-1.9.0-bin.tar.gz 到 /opt/module/ 目录下

```shell
[atguigu@hadoop102 software]$ tar -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/
```

3）修改apache-flume-1.9.0-bin的名称为flume

```shell
[atguigu@hadoop102 module]$ mv /opt/module/apache-flume-1.9.0-bin /opt/module/flume
```

4）将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3

```shell
rm /opt/module/flume/lib/guava-11.0.2.jar
```

注意：删除guava-11.0.2.jar的服务器节点，一定要配置hadoop环境变量。否则会报如下异常。

```java
Caused by: java.lang.ClassNotFoundException: com.google.common.collect.Lists
        at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:349)
        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
        ... 1 more
```

5）将flume/conf下的flume-env.sh.template文件修改为flume-env.sh，并配置flume-env.sh文件

```shell
[atguigu@hadoop102 conf]$ mv flume-env.sh.template flume-env.sh

[atguigu@hadoop102 conf]$ vi flume-env.sh
export JAVA_HOME=/opt/module/jdk1.8.0_212
```



## 八、模拟日志的生成

### 8.1、模拟生成log日志

将application.properties、gmall2020-mock-log-2020-04-01.jar、path2.json上传到hadoop102的/opt/module/applog目录下

![img](https://gitee.com/wangzj6666666/bigdata-img/raw/master/data_warehouse_offline/wps1.jpg) 

2）配置文件

- application.properteis文件

可以根据需求生成对应日期的用户行为日志。

```txt
logging.level.root=info
#业务日期
mock.date=2020-03-10

#启动次数
mock.startup.count=100
#设备最大值
mock.max.mid=50
#会员最大值
mock.max.uid=500
#商品最大值
mock.max.sku-id=10
#页面平均访问时间
mock.page.during-time-ms=20000
#错误概率
mock.error.rate=3
#日志发送延迟
mock.log.sleep=100
#商品详情来源  用户查询，商品推广，智能推荐, 促销活动
mock.detail.source-type-rate=40:25:15:20
```

- path2.json，该文件用来配置访问路径

- 日志生成命令

在/opt/module/applog路径下执行日志生成命令。

```shell
[atguigu@hadoop102 applog]$ java -jar gmall2020-mock-log-2020-04-01.jar
```

- 在/opt/module/applog/log目录下查看生成日志

```shell
[atguigu@hadoop102 log]$ ll
```

### 8.2、集群日志生成脚本

hadoop102、hadoop103 负责生产日志

1）在/home/atguigu/bin目录下创建脚本lg.sh

```shell
[atguigu@hadoop102 bin]$ vim /home/atguigu/bin/log.sh
```

2）在脚本中编写如下内容

```shell
#!/bin/bash
for i in hadoop102 hadoop103; do
    echo "========== $i =========="
    ssh $i "cd /opt/module/applog/; java -jar gmall2020-mock-log-2020-04-01.jar >/dev/null 2>&1 &"
done 
```

注：

- /opt/module/applog/为jar包及配置文件所在路径
- /dev/null代表linux的空设备文件，所有往这个文件里面写入的内容都会丢失，俗称“黑洞”。
  - 标准输入0：从键盘获得输入 /proc/self/fd/0 
  - 标准输出1：输出到屏幕（即控制台） /proc/self/fd/1 
  - 错误输出2：输出到屏幕（即控制台） /proc/self/fd/2

3）修改脚本执行权限

```shell
[atguigu@hadoop102 bin]$ chmod 777 log.sh
```

4）将jar包及配置文件上传至hadoop103的/opt/module/applog/路径

5）启动脚本

```shell
[atguigu@hadoop102 module]$ log.sh 
```

6）分别在hadoop102、hadoop103的/tmp/logs目录上查看生成的数据

```shell
[atguigu@hadoop102 logs]$ ls
```

app.2020-03-10.log

```shell
[atguigu@hadoop103 logs]$ ls
```

app.2020-03-10.log



### 8.3、日志采集Flume配置

![1593747226739](https://gitee.com/wangzj6666666/bigdata-img/raw/master/data_warehouse_offline/1593747226739.png)

1）在/opt/module/flume/conf目录下创建file-flume-kafka.conf文件

```txt
#为各组件命名
a1.sources = r1
a1.channels = c1

#描述source
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*
a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json
a1.sources.r1.interceptors =  i1
a1.sources.r1.interceptors.i1.type = com.atguigu.flume.interceptor.LogInterceptor$Builder

#描述channel
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092
a1.channels.c1.kafka.topic = topic_log
a1.channels.c1.parseAsFlumeEvent = false

#绑定source和channel以及sink和channel的关系
a1.sources.r1.channels = c1
```

注意：com.atguigu.flume.interceptor.LogInterceptor 是  拦截器 的全类名



### 8.4、Flume拦截器

1）创建Maven工程flume-interceptor

2）创建包名：com.atguigu.flume.interceptor

3）在pom.xml文件中添加如下配置

```xml
<dependencies>
    <dependency>
        <groupId>org.apache.flume</groupId>
        <artifactId>flume-ng-core</artifactId>
        <version>1.9.0</version>
        <scope>provided</scope>
    </dependency>

    <dependency>
        <groupId>com.alibaba</groupId>
        <artifactId>fastjson</artifactId>
        <version>1.2.62</version>
    </dependency>

</dependencies>

<build>
    <plugins>
        <plugin>
            <artifactId>maven-compiler-plugin</artifactId>
            <version>2.3.2</version>
            <configuration>
                <source>1.8</source>
                <target>1.8</target>
            </configuration>
        </plugin>
        <plugin>
            <artifactId>maven-assembly-plugin</artifactId>
            <configuration>
                <descriptorRefs>
                    <descriptorRef>jar-with-dependencies</descriptorRef>
                </descriptorRefs>
            </configuration>
            <executions>
                <execution>
                    <id>make-assembly</id>
                    <phase>package</phase>
                    <goals>
                        <goal>single</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>

```

4）在com.atguigu.flume.interceptor包下创建LogInterceptor类名

```java
package com.atguigu.flume.interceptor;

import com.alibaba.fastjson.JSON;
import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.interceptor.Interceptor;

import java.nio.charset.StandardCharsets;
import java.util.Iterator;
import java.util.List;

public class LogInterceptor implements Interceptor {
    @Override
    public void initialize() {

    }

    @Override
    public Event intercept(Event event) {

        byte[] body = event.getBody();
        String log = new String(body, StandardCharsets.UTF_8);

        if (JSON.isValid(log)) {
            return event;
        } else {
            return null;
        }
    }

    @Override
    public List<Event> intercept(List<Event> list) {

        Iterator<Event> iterator = list.iterator();
        while (iterator.hasNext()) {
            Event next = iterator.next();
            if (intercept(next) == null) {
                iterator.remove();
            }
        }
        return list;
    }

    @Override
    public void close() {

    }

    public static class Builder implements Interceptor.Builder {

        @Override
        public Interceptor build() {
            return new LogInterceptor();
        }

        @Override
        public void configure(Context context) {

        }
    }
}
```

6）打包

![1593747418857](https://gitee.com/wangzj6666666/bigdata-img/raw/master/data_warehouse_offline/image-20200804203735909.png)                          

7）需要先将打好的包放入到hadoop102的/opt/module/flume/lib文件夹下面。

```shell
[atguigu@hadoop102 lib]$ ls | grep interceptor

flume-interceptor-1.0-SNAPSHOT-jar-with-dependencies.jar
```

8）分发Flume到hadoop103、hadoop104

```shell
[atguigu@hadoop102 module]$ xsync flume/
```



### 8.5、日志采集Flume启动停止脚本

1）在/home/atguigu/bin目录下创建脚本f1.sh

```shell
[atguigu@hadoop102 bin]$ vim f1.sh
```

在脚本中填写如下内容

```shell
 #! /bin/bash

case $1 in
"start"){
        for i in hadoop102 hadoop103
        do
                echo " --------启动 $i 采集flume-------"
                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/file-flume-kafka.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log1.txt 2>&1  &"
        done
};;	
"stop"){
        for i in hadoop102 hadoop103
        do
                echo " --------停止 $i 采集flume-------"
                ssh $i "ps -ef | grep file-flume-kafka | grep -v grep |awk  '{print \$2}' | xargs -n1 kill -9 "
        done

};;
esac
```

说明1：nohup，该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思，不挂断地运行命令。

说明2：awk 默认分隔符为空格

说明3：xargs 表示取出前面命令运行的结果，作为后面命令的输入参数。

2）增加脚本执行权限

```
[atguigu@hadoop102 bin]$ chmod 777 f1.sh
```

3）f1集群启动脚本

```shell
[atguigu@hadoop102 module]$ f1.sh start
```

4）f1集群停止脚本

```shell
[atguigu@hadoop102 module]$ f1.sh stop
```



### 8.6、日志消费Flume配置

1）Flume配置分析

![1593747704258](https://gitee.com/wangzj6666666/bigdata-img/raw/master/data_warehouse_offline/1593747704258.png)

2）Flume的具体配置如下：

在hadoop104的/opt/module/flume/conf目录下创建kafka-flume-hdfs.conf文件

```shell
[atguigu@hadoop104 conf]$ vim kafka-flume-hdfs.conf
```

在文件配置如下内容

```shell
## 组件
a1.sources=r1
a1.channels=c1
a1.sinks=k1

## source1
a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
a1.sources.r1.batchSize = 5000
a1.sources.r1.batchDurationMillis = 2000
a1.sources.r1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.sources.r1.kafka.topics=topic_log


## channel1
a1.channels.c1.type = file
a1.channels.c1.checkpointDir = /opt/module/flume/checkpoint/behavior1
a1.channels.c1.dataDirs = /opt/module/flume/data/behavior1/
a1.channels.c1.maxFileSize = 2146435071
a1.channels.c1.capacity = 1000000
a1.channels.c1.keep-alive = 6


## sink1
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = /origin_data/gmall/log/topic_log/%Y-%m-%d
a1.sinks.k1.hdfs.filePrefix = log-
a1.sinks.k1.hdfs.round = false


a1.sinks.k1.hdfs.rollInterval = 10
a1.sinks.k1.hdfs.rollSize = 134217728
a1.sinks.k1.hdfs.rollCount = 0

## 控制输出文件是原生文件。
a1.sinks.k1.hdfs.fileType = CompressedStream
a1.sinks.k1.hdfs.codeC = lzop

## 拼装
a1.sources.r1.channels = c1
a1.sinks.k1.channel= c1

```

### 8.7、日志消费Flume启动停止脚本

1）在/home/atguigu/bin目录下创建脚本f2.sh

```shell
[atguigu@hadoop102 bin]$ vim f2.sh
```

在脚本中填写如下内容

```shell
#! /bin/bash

case $1 in
"start"){
        for i in hadoop104
        do
                echo " --------启动 $i 消费flume-------"
                ssh $i "nohup /opt/module/flume/bin/flume-ng agent --conf-file /opt/module/flume/conf/kafka-flume-hdfs.conf --name a1 -Dflume.root.logger=INFO,LOGFILE >/opt/module/flume/log2.txt   2>&1 &"
        done
};;
"stop"){
        for i in hadoop104
        do
                echo " --------停止 $i 消费flume-------"
                ssh $i "ps -ef | grep kafka-flume-hdfs | grep -v grep |awk '{print \$2}' | xargs -n1 kill"
        done

};;
esac
```

2）增加脚本执行权限

```shell
[atguigu@hadoop102 bin]$ chmod 777 f2.sh
```

3）f2集群启动脚本

```shell
[atguigu@hadoop102 module]$ f2.sh start
```

4）f2集群停止脚本

```shell
[atguigu@hadoop102 module]$ f2.sh stop
```



### 8.8、采集通道启动/停止脚本

1）在/home/atguigu/bin目录下创建脚本cluster.sh

```shell
[atguigu@hadoop102 bin]$ vim cluster.sh
```

在脚本中填写如下内容

```shell
#! /bin/bash

case $1 in
"start"){
	echo " -------- 启动 集群 -------"

	echo " -------- 启动 hadoop集群 -------"
	/opt/module/hadoop-3.1.3/sbin/start-dfs.sh 
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/start-yarn.sh"

	#启动 Zookeeper集群
	zk.sh start

sleep 4s;

	#启动 Flume采集集群
	f1.sh start

	#启动 Kafka采集集群
	kf.sh start

sleep 6s;

	#启动 Flume消费集群
	f2.sh start

	};;
"stop"){
    echo " -------- 停止 集群 -------"


    #停止 Flume消费集群
	f2.sh stop

	#停止 Kafka采集集群
	kf.sh stop

    sleep 6s;

	#停止 Flume采集集群
	f1.sh stop

	#停止 Zookeeper集群
	zk.sh stop

	echo " -------- 停止 hadoop集群 -------"
	ssh hadoop103 "/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh"
	/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh 
};;
esac
```

2）增加脚本执行权限

```shell
[atguigu@hadoop102 bin]$ chmod 777 cluster.sh
```

3）cluster集群启动脚本

```she&#39;l&#39;l
[atguigu@hadoop102 module]$ cluster.sh start
```

4）cluster集群停止脚本

```shell
[atguigu@hadoop102 module]$ cluster.sh stop
```



### 8.9、数据通道测试

当hadoop、zookeeper、kafka、flume、applog都配好，启动采集通道cluster.sh start

1）根据需求生成指定日期的数据，需要先调整服务器时间

注意：调整服务器时间，需要重新启动集群

```shell
[atguigu@hadoop102 ~]$ dt.sh 2020-07-03
```

2）生成日志数据

```
[atguigu@hadoop102 ~]$ log.sh
```

3）观察Hadoop的HDFS路径上是否有数据

![1593750192001](https://gitee.com/wangzj6666666/bigdata-img/raw/master/data_warehouse_offline/1593750192001.png)





